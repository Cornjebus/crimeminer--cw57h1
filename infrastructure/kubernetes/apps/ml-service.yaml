# Kubernetes manifest for CrimeMiner ML service deployment
# Implements FedRAMP High compliant ML processing with GPU acceleration
# Version: 1.27+

---
apiVersion: v1
kind: ServiceAccount
metadata:
  name: ml-service
  namespace: crimeminer-ml
  labels:
    app.kubernetes.io/name: ml-service
    app.kubernetes.io/part-of: crimeminer
    compliance-level: fedramp-high

---
apiVersion: v1
kind: Service
metadata:
  name: ml-service
  namespace: crimeminer-ml
  labels:
    app: ml-service
    compliance-level: fedramp-high
  annotations:
    prometheus.io/scrape: "true"
    prometheus.io/port: "3000"
    prometheus.io/path: "/metrics"
spec:
  ports:
    - port: 3000
      targetPort: 3000
      protocol: TCP
      name: http
  selector:
    app: ml-service

---
apiVersion: apps/v1
kind: Deployment
metadata:
  name: ml-service
  namespace: crimeminer-ml
  labels:
    app: ml-service
    compliance-level: fedramp-high
    data-classification: sensitive-law-enforcement
spec:
  replicas: 3
  selector:
    matchLabels:
      app: ml-service
      compliance-level: fedramp-high
  strategy:
    type: RollingUpdate
    rollingUpdate:
      maxSurge: 1
      maxUnavailable: 0
  template:
    metadata:
      labels:
        app: ml-service
        compliance-level: fedramp-high
        data-classification: sensitive-law-enforcement
      annotations:
        compliance.fedramp.gov/control-baseline: "high"
        security.istio.io/tlsMode: "istio"
        prometheus.io/scrape: "true"
        prometheus.io/port: "3000"
        prometheus.io/path: "/metrics"
    spec:
      serviceAccountName: ml-service
      securityContext:
        fsGroup: 1000
        runAsNonRoot: true
        seccompProfile:
          type: RuntimeDefault
      initContainers:
        - name: gpu-validation
          image: nvidia/cuda:11.8.0-base-ubuntu22.04
          command: ["nvidia-smi"]
          securityContext:
            runAsNonRoot: true
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
            capabilities:
              drop: ["ALL"]
      containers:
        - name: ml-service
          image: crimeminer/ml-service:latest
          imagePullPolicy: Always
          ports:
            - containerPort: 3000
              protocol: TCP
          resources:
            requests:
              cpu: "4"
              memory: "16Gi"
              nvidia.com/gpu: "1"
            limits:
              cpu: "8"
              memory: "32Gi"
              nvidia.com/gpu: "2"
          securityContext:
            runAsNonRoot: true
            readOnlyRootFilesystem: true
            allowPrivilegeEscalation: false
            seccompProfile:
              type: RuntimeDefault
            capabilities:
              drop: ["ALL"]
          volumeMounts:
            - name: tmp
              mountPath: /tmp
              readOnly: false
            - name: model-store
              mountPath: /models
              readOnly: true
          livenessProbe:
            httpGet:
              path: /health/live
              port: 3000
            initialDelaySeconds: 30
            periodSeconds: 10
          readinessProbe:
            httpGet:
              path: /health/ready
              port: 3000
            initialDelaySeconds: 15
            periodSeconds: 5
          env:
            - name: ENVIRONMENT
              value: "production"
            - name: LOG_LEVEL
              value: "info"
            - name: COMPLIANCE_LEVEL
              value: "fedramp-high"
      volumes:
        - name: tmp
          emptyDir: {}
        - name: model-store
          persistentVolumeClaim:
            claimName: ml-models-pvc
      affinity:
        podAntiAffinity:
          requiredDuringSchedulingIgnoredDuringExecution:
            - labelSelector:
                matchExpressions:
                  - key: app
                    operator: In
                    values: ["ml-service"]
              topologyKey: kubernetes.io/hostname
      topologySpreadConstraints:
        - maxSkew: 1
          topologyKey: topology.kubernetes.io/zone
          whenUnsatisfiable: DoNotSchedule
          labelSelector:
            matchLabels:
              app: ml-service
      nodeSelector:
        nvidia.com/gpu: "true"
        compliance-level: fedramp-high

---
apiVersion: autoscaling/v2
kind: HorizontalPodAutoscaler
metadata:
  name: ml-service
  namespace: crimeminer-ml
spec:
  scaleTargetRef:
    apiVersion: apps/v1
    kind: Deployment
    name: ml-service
  minReplicas: 3
  maxReplicas: 10
  metrics:
    - type: Resource
      resource:
        name: cpu
        target:
          type: Utilization
          averageUtilization: 70
    - type: Resource
      resource:
        name: memory
        target:
          type: Utilization
          averageUtilization: 80

---
apiVersion: policy/v1
kind: PodDisruptionBudget
metadata:
  name: ml-service
  namespace: crimeminer-ml
spec:
  minAvailable: 2
  selector:
    matchLabels:
      app: ml-service